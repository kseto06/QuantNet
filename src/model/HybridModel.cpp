#include "HybridModel.h"
#include "MLP.h"
#include "LSTMNetwork.h"
#include "activations.h"

#include <cmath>
#include <vector>
#include <map>

#include "linalg.h"

namespace HybridModel {
    typedef std::vector<std::vector<double>> Matrix;
    typedef std::vector<std::vector<std::vector<double>>> Tensor3D;
    typedef std::variant<Matrix, Tensor3D> variantTensor;
    typedef std::map<std::string, Matrix> matrixDict; //Global params
    typedef std::vector<matrixDict> MLPCache; //cache for forward prop

    //LSTM
    typedef std::tuple<Matrix, Matrix, Matrix, Matrix, Matrix, Matrix, Matrix, Matrix, Matrix, matrixDict> cacheTuple;
    typedef std::tuple<Tensor3D, Tensor3D, Tensor3D, std::tuple<std::vector<cacheTuple>, Tensor3D>> LSTMCache;

    //Unified cache structure
    struct UnifiedCache {
        MLPCache mlpCache;
        std::vector<LSTMCache> lstmCache;
    };

    //Anonymous namespace for private variables
    namespace {
        //Default layer types (i.e. Dense LSTM) and layer dimensions
        std::vector<std::string> layer_types = {};
        std::vector<int> layer_dims = {};
        std::vector<matrixDict> layer_params;

        //Forward prop variables
        UnifiedCache cache;
        Matrix finalPrediction; //Linear output matrix, shape(m,1)

        //Loss
        double accumulated_loss = 0.0;

        //Data, x_train and y_train. NOTE: x_train and y_train have to be generated by minibatches
        variantTensor x_train;
        Matrix y_train = {{}}; //shape (m,1)
        const int BATCH_SIZE = 64;
    }

    // MSE loss function
    double MSE(const std::vector<double>& pred, const std::vector<double>& target) {
        double loss = 0.0;
        for (size_t i = 0; i < pred.size(); i++) {
            loss += std::pow(pred[i] - target[i], 2);
        }
        return loss/pred.size();
    }

    //Layer types and dimensions (setters)
    void init_layers(const std::vector<std::string>& layer_type, const std::vector<int>& layer_dim) {
        layer_types = layer_type;
        layer_dims = layer_dim;
    }

    //LSTM Network initialization
    void initialize_network() {
        //NOTE: layer_type and layer_dims should have the same shape
        for (int i = 1; i <= layer_types.size(); i++) {
            matrixDict current_params;
            if (layer_types[i] == "LSTM") {
                current_params = LSTMNetwork::init_params(BATCH_SIZE, std::get<Tensor3D>(x_train)[0].size(), layer_dims[i], i); //Output matches the input shape?
            } else if (layer_types[i] == "Relu" || layer_types[i] == "Linear") {
                current_params = MLP::init_mlp_params(layer_dims, i);
            }
            layer_params.push_back(current_params);
        }
    }

    //Tensor3D --> Matrix conversion based on last timestep output
    Matrix reshape_last_timestep(const Tensor3D& hidden_state) {
        int batch_size = hidden_state.size();
        int hidden_units = hidden_state[0][0].size();
        Matrix reshaped_matrix(batch_size, std::vector<double>(hidden_units));

        // Extract the last timestep for each example in the batch
        for (int i = 0; i < batch_size; ++i) {
            reshaped_matrix[i] = hidden_state[i].back();  // last timestep
        }
        return reshaped_matrix;
    }

    void forward_prop() {
        Matrix Wy = layer_params[0]["Wy1"];
        int n_a = Wy[0].size();

        //MLP
        Matrix a_out;

        //LSTM
        Matrix a_initial = linalg::generateZeros(std::get<Tensor3D>(x_train).size(), n_a); //Initially, a0 is a Matrix of zeros with shape (m, n_a)
        Tensor3D new_x_state;
        Tensor3D new_hidden_state;

        for (int i = 1; i <= layer_types.size(); i++) {
            if (layer_types[i] == "LSTM") {
                if (i == 1) {
                    LSTMCache current_lstm_tuple = LSTMNetwork::lstm_forward(std::get<Tensor3D>(x_train), a_initial, layer_params[i], i);
                    //lstm_forward returns: std::make_tuple(hidden_state, prediction, candidate, std::make_tuple(cache, x));
                    new_x_state = std::get<1>(std::get<3>(current_lstm_tuple));
                    new_hidden_state = std::get<0>(current_lstm_tuple);
                    cache.lstmCache.push_back(current_lstm_tuple);
                } else {
                    LSTMCache current_lstm_tuple = LSTMNetwork::lstm_forward(new_x_state, reshape_last_timestep(new_hidden_state), layer_params[i], i);
                    //lstm_forward returns: std::make_tuple(hidden_state, prediction, candidate, std::make_tuple(cache, x));
                    new_x_state = std::get<1>(std::get<3>(current_lstm_tuple));
                    new_hidden_state = std::get<0>(current_lstm_tuple);
                    cache.lstmCache.push_back(current_lstm_tuple);
                }
            } else if (layer_types[i] == "Relu") {
                // Reshape a_out using the last timestepped hidden state from LSTM_forward
                if (layer_types[i-1] == "LSTM" && i != 1) {
                    a_out = reshape_last_timestep(new_hidden_state);
                }

                if (i == 1) {
                    //Input x is a Matrix
                    std::tuple<Matrix, matrixDict> current_dense_tuple = MLP::Dense(std::get<Matrix>(x_train), layer_params[i], activations::relu, i, cache.mlpCache[i]);
                    a_out = std::get<0>(current_dense_tuple);
                    matrixDict current_mlp_cache = std::get<1>(current_dense_tuple);
                    cache.mlpCache.push_back(current_mlp_cache);
                } else {
                    std::tuple<Matrix, matrixDict> current_dense_tuple = MLP::Dense(a_out, layer_params[i], activations::relu, i, cache.mlpCache[i]);
                    a_out = std::get<0>(current_dense_tuple);
                    matrixDict current_mlp_cache = std::get<1>(current_dense_tuple);
                    cache.mlpCache.push_back(current_mlp_cache);
                }
            } else if (layer_types[i] == "Linear") {
                // Reshape a_out using the last timestepped hidden state from LSTM_forward
                if (layer_types[i-1] == "LSTM" && i != 1) {
                    a_out = reshape_last_timestep(new_hidden_state);
                }

                std::tuple<Matrix, matrixDict> current_dense_tuple = MLP::Dense(a_out, layer_params[i], activations::linear, i, cache.mlpCache[i]);
                a_out = std::get<0>(current_dense_tuple);
                matrixDict current_mlp_cache = std::get<1>(current_dense_tuple);
                cache.mlpCache.push_back(current_mlp_cache);
            }
        }
        //Set the final prediction matrix
        finalPrediction = a_out;
    }

    void loss() {
        std::vector<double> predictions = linalg::reshape(finalPrediction);
        std::vector<double> targets = linalg::reshape(y_train);

        //predictions and current y_train are of the same mini-batch (BATCH_SIZE = 64):
        accumulated_loss += MSE(predictions, targets);
    }

    void back_prop() {
        //TO-DO
    }
}
